{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD \n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "# import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold as kfold\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn import linear_model\n",
    "from scipy.sparse import vstack, hstack, csr_matrix, load_npz\n",
    "from nltk.corpus import stopwords \n",
    "# from Levenshtein import  jaro_winkler\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = pd.read_csv('../hasil/5_train_data_1000_25_06122023.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "training = pd.read_csv('../hasil/traindata_lexicon.csv')\n",
    "# traindex = training.index\n",
    "testing = pd.read_csv('../hasil/testdata_lexicon.csv')\n",
    "# testdex = testing.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagus sekali pemandangan hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content\n",
       "0                  Bagus sekali pemandangan hari ini\n",
       "1      aku bisa makan pagi enak kenyang mantab sehat\n",
       "2  makanan ini sangat enak lezat mantab aku suka ...\n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...\n",
       "4        saat ini aku sangat kesal dan sangat capek "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spath = 'sentilex-id/'\n",
    "# sentiment_id_n = pd.read_csv(spath + 'negative_words_id.txt').rename(columns={'время':'Words'})\n",
    "sentiment_id_n = pd.read_csv(spath + 'negative_words_id.txt')\n",
    "sentiment_id_n['Polarity'] = -1\n",
    "sentiment_id_p = pd.read_csv(spath + 'positive_words_id.txt')\n",
    "sentiment_id_p['Polarity'] = 1\n",
    "sentiment_id = pd.concat([sentiment_id_n, sentiment_id_p], ignore_index=True)\n",
    "sentiment_id_vect = CountVectorizer()\n",
    "sentiment_id2 = sentiment_id_vect.fit_transform(sentiment_id['Words'])\n",
    "sentiment_id_model = linear_model.LinearRegression(n_jobs=-1).fit(sentiment_id2, sentiment_id['Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_id_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(s):\n",
    "    return sentiment_id_model.predict(sentiment_id_vect.transform([s]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_cols = ['clean_content']\n",
    "for c in senti_cols:\n",
    "    training[c + '_Pol'] = training[c].map(lambda x: getSentiment(str(x))) #getSentiment\n",
    "    testing[c + '_Pol'] = testing[c].map(lambda x: getSentiment(str(x))) #getSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "      <th>clean_content_Pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagus sekali pemandangan hari ini</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "      <td>1.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "      <td>4.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orang ini sangat menyebalkan karena dia telah ...</td>\n",
       "      <td>-3.224138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aku anak sehat tubuhku kuat karena ibuku rajin...</td>\n",
       "      <td>6.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content  clean_content_Pol\n",
       "0                  Bagus sekali pemandangan hari ini           0.258621\n",
       "1      aku bisa makan pagi enak kenyang mantab sehat           1.517241\n",
       "2  makanan ini sangat enak lezat mantab aku suka ...           4.034483\n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...           0.258621\n",
       "4        saat ini aku sangat kesal dan sangat capek           -1.000000\n",
       "5  orang ini sangat menyebalkan karena dia telah ...          -3.224138\n",
       "6  aku anak sehat tubuhku kuat karena ibuku rajin...           6.034483"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(training[:1])\n",
    "training.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([training,testing],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "      <th>clean_content_Pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagus sekali pemandangan hari ini</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "      <td>1.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "      <td>4.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orang ini sangat menyebalkan karena dia telah ...</td>\n",
       "      <td>-3.224138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aku anak sehat tubuhku kuat karena ibuku rajin...</td>\n",
       "      <td>6.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagus sekali pemandangan hari ini</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "      <td>1.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "      <td>4.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "      <td>0.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orang ini sangat menyebalkan karena dia telah ...</td>\n",
       "      <td>-3.224138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aku anak sehat tubuhku kuat karena ibuku rajin...</td>\n",
       "      <td>6.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content  clean_content_Pol\n",
       "0                  Bagus sekali pemandangan hari ini           0.258621\n",
       "1      aku bisa makan pagi enak kenyang mantab sehat           1.517241\n",
       "2  makanan ini sangat enak lezat mantab aku suka ...           4.034483\n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...           0.258621\n",
       "4        saat ini aku sangat kesal dan sangat capek           -1.000000\n",
       "5  orang ini sangat menyebalkan karena dia telah ...          -3.224138\n",
       "6  aku anak sehat tubuhku kuat karena ibuku rajin...           6.034483\n",
       "0                  Bagus sekali pemandangan hari ini           0.258621\n",
       "1      aku bisa makan pagi enak kenyang mantab sehat           1.517241\n",
       "2  makanan ini sangat enak lezat mantab aku suka ...           4.034483\n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...           0.258621\n",
       "4        saat ini aku sangat kesal dan sangat capek           -1.000000\n",
       "5  orang ini sangat menyebalkan karena dia telah ...          -3.224138\n",
       "6  aku anak sehat tubuhku kuat karena ibuku rajin...           6.034483"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Data shape: 14 Rows, 2 Columns\n"
     ]
    }
   ],
   "source": [
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_punc'] = df['clean_content'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "      <th>clean_content_Pol</th>\n",
       "      <th>clean_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagus sekali pemandangan hari ini</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content  clean_content_Pol  \\\n",
       "0                  Bagus sekali pemandangan hari ini           0.258621   \n",
       "1      aku bisa makan pagi enak kenyang mantab sehat           1.517241   \n",
       "2  makanan ini sangat enak lezat mantab aku suka ...           4.034483   \n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...           0.258621   \n",
       "4        saat ini aku sangat kesal dan sangat capek           -1.000000   \n",
       "\n",
       "   clean_punc  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Menambahkan fitur selain TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"clean_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('missing') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n",
    "    df[cols + '_num_letters'] = df[cols].apply(lambda comment: len(comment)) # Count number of Letters\n",
    "\n",
    "# Extra Feature Engineering\n",
    "# df['title_desc_len_ratio'] = df['title_num_letters']/df['description_num_letters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_content</th>\n",
       "      <th>clean_content_Pol</th>\n",
       "      <th>clean_punc</th>\n",
       "      <th>clean_content_num_words</th>\n",
       "      <th>clean_content_num_unique_words</th>\n",
       "      <th>clean_content_words_vs_unique</th>\n",
       "      <th>clean_content_num_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bagus sekali pemandangan hari ini</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku bisa makan pagi enak kenyang mantab sehat</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>makanan ini sangat enak lezat mantab aku suka ...</td>\n",
       "      <td>4.034483</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku sangat menginginkan ini jadi aku akan kemb...</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saat ini aku sangat kesal dan sangat capek</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_content  clean_content_Pol  \\\n",
       "0                  bagus sekali pemandangan hari ini           0.258621   \n",
       "1      aku bisa makan pagi enak kenyang mantab sehat           1.517241   \n",
       "2  makanan ini sangat enak lezat mantab aku suka ...           4.034483   \n",
       "3  aku sangat menginginkan ini jadi aku akan kemb...           0.258621   \n",
       "4        saat ini aku sangat kesal dan sangat capek           -1.000000   \n",
       "\n",
       "   clean_punc  clean_content_num_words  clean_content_num_unique_words  \\\n",
       "0           0                        5                               5   \n",
       "1           0                        8                               8   \n",
       "2           0                        9                               9   \n",
       "3           0                       13                              12   \n",
       "4           0                        8                               7   \n",
       "\n",
       "   clean_content_words_vs_unique  clean_content_num_letters  \n",
       "0                     100.000000                         33  \n",
       "1                     100.000000                         45  \n",
       "2                     100.000000                         52  \n",
       "3                      92.307692                         73  \n",
       "4                      87.500000                         43  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Term Frequency Inverse Document Frequency Stage\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "id_stop = set(stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_para = {\n",
    "    \"stop_words\": id_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col(col_name): return lambda x: x[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = FeatureUnion([\n",
    "        ('clean_content',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=17000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('clean_content'))),\n",
    "        # ('title',CountVectorizer(\n",
    "        #     ngram_range=(1, 2),\n",
    "        #     stop_words = russian_stop,\n",
    "        #     max_features=130000,\n",
    "        #     preprocessor=get_col('title')))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureUnion(transformer_list=[(&#x27;clean_content&#x27;,\n",
       "                                TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;,\n",
       "                                                max_features=17000,\n",
       "                                                ngram_range=(1, 2),\n",
       "                                                preprocessor=&lt;function get_col.&lt;locals&gt;.&lt;lambda&gt; at 0x000001EF697A76D0&gt;,\n",
       "                                                smooth_idf=False,\n",
       "                                                stop_words={&#x27;ada&#x27;, &#x27;adalah&#x27;,\n",
       "                                                            &#x27;adanya&#x27;, &#x27;adapun&#x27;,\n",
       "                                                            &#x27;agak&#x27;, &#x27;agaknya&#x27;,\n",
       "                                                            &#x27;agar&#x27;, &#x27;akan&#x27;,\n",
       "                                                            &#x27;akankah&#x27;, &#x27;akhir&#x27;,\n",
       "                                                            &#x27;akhiri&#x27;,\n",
       "                                                            &#x27;akhirnya&#x27;, &#x27;aku&#x27;,\n",
       "                                                            &#x27;akulah&#x27;, &#x27;amat&#x27;,\n",
       "                                                            &#x27;amatlah&#x27;, &#x27;anda&#x27;,\n",
       "                                                            &#x27;andalah&#x27;, &#x27;antar&#x27;,\n",
       "                                                            &#x27;antara&#x27;,\n",
       "                                                            &#x27;antaranya&#x27;, &#x27;apa&#x27;,\n",
       "                                                            &#x27;apaan&#x27;, &#x27;apabila&#x27;,\n",
       "                                                            &#x27;apakah&#x27;, &#x27;apalagi&#x27;,\n",
       "                                                            &#x27;apatah&#x27;, &#x27;artinya&#x27;,\n",
       "                                                            &#x27;asal&#x27;, &#x27;asalkan&#x27;, ...},\n",
       "                                                sublinear_tf=True,\n",
       "                                                token_pattern=&#x27;\\\\w{1,}&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;clean_content&#x27;,\n",
       "                                TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;,\n",
       "                                                max_features=17000,\n",
       "                                                ngram_range=(1, 2),\n",
       "                                                preprocessor=&lt;function get_col.&lt;locals&gt;.&lt;lambda&gt; at 0x000001EF697A76D0&gt;,\n",
       "                                                smooth_idf=False,\n",
       "                                                stop_words={&#x27;ada&#x27;, &#x27;adalah&#x27;,\n",
       "                                                            &#x27;adanya&#x27;, &#x27;adapun&#x27;,\n",
       "                                                            &#x27;agak&#x27;, &#x27;agaknya&#x27;,\n",
       "                                                            &#x27;agar&#x27;, &#x27;akan&#x27;,\n",
       "                                                            &#x27;akankah&#x27;, &#x27;akhir&#x27;,\n",
       "                                                            &#x27;akhiri&#x27;,\n",
       "                                                            &#x27;akhirnya&#x27;, &#x27;aku&#x27;,\n",
       "                                                            &#x27;akulah&#x27;, &#x27;amat&#x27;,\n",
       "                                                            &#x27;amatlah&#x27;, &#x27;anda&#x27;,\n",
       "                                                            &#x27;andalah&#x27;, &#x27;antar&#x27;,\n",
       "                                                            &#x27;antara&#x27;,\n",
       "                                                            &#x27;antaranya&#x27;, &#x27;apa&#x27;,\n",
       "                                                            &#x27;apaan&#x27;, &#x27;apabila&#x27;,\n",
       "                                                            &#x27;apakah&#x27;, &#x27;apalagi&#x27;,\n",
       "                                                            &#x27;apatah&#x27;, &#x27;artinya&#x27;,\n",
       "                                                            &#x27;asal&#x27;, &#x27;asalkan&#x27;, ...},\n",
       "                                                sublinear_tf=True,\n",
       "                                                token_pattern=&#x27;\\\\w{1,}&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>clean_content</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, max_features=17000,\n",
       "                ngram_range=(1, 2),\n",
       "                preprocessor=&lt;function get_col.&lt;locals&gt;.&lt;lambda&gt; at 0x000001EF697A76D0&gt;,\n",
       "                smooth_idf=False,\n",
       "                stop_words={&#x27;ada&#x27;, &#x27;adalah&#x27;, &#x27;adanya&#x27;, &#x27;adapun&#x27;, &#x27;agak&#x27;,\n",
       "                            &#x27;agaknya&#x27;, &#x27;agar&#x27;, &#x27;akan&#x27;, &#x27;akankah&#x27;, &#x27;akhir&#x27;,\n",
       "                            &#x27;akhiri&#x27;, &#x27;akhirnya&#x27;, &#x27;aku&#x27;, &#x27;akulah&#x27;, &#x27;amat&#x27;,\n",
       "                            &#x27;amatlah&#x27;, &#x27;anda&#x27;, &#x27;andalah&#x27;, &#x27;antar&#x27;, &#x27;antara&#x27;,\n",
       "                            &#x27;antaranya&#x27;, &#x27;apa&#x27;, &#x27;apaan&#x27;, &#x27;apabila&#x27;, &#x27;apakah&#x27;,\n",
       "                            &#x27;apalagi&#x27;, &#x27;apatah&#x27;, &#x27;artinya&#x27;, &#x27;asal&#x27;, &#x27;asalkan&#x27;, ...},\n",
       "                sublinear_tf=True, token_pattern=&#x27;\\\\w{1,}&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "FeatureUnion(transformer_list=[('clean_content',\n",
       "                                TfidfVectorizer(dtype=<class 'numpy.float32'>,\n",
       "                                                max_features=17000,\n",
       "                                                ngram_range=(1, 2),\n",
       "                                                preprocessor=<function get_col.<locals>.<lambda> at 0x000001EF697A76D0>,\n",
       "                                                smooth_idf=False,\n",
       "                                                stop_words={'ada', 'adalah',\n",
       "                                                            'adanya', 'adapun',\n",
       "                                                            'agak', 'agaknya',\n",
       "                                                            'agar', 'akan',\n",
       "                                                            'akankah', 'akhir',\n",
       "                                                            'akhiri',\n",
       "                                                            'akhirnya', 'aku',\n",
       "                                                            'akulah', 'amat',\n",
       "                                                            'amatlah', 'anda',\n",
       "                                                            'andalah', 'antar',\n",
       "                                                            'antara',\n",
       "                                                            'antaranya', 'apa',\n",
       "                                                            'apaan', 'apabila',\n",
       "                                                            'apakah', 'apalagi',\n",
       "                                                            'apatah', 'artinya',\n",
       "                                                            'asal', 'asalkan', ...},\n",
       "                                                sublinear_tf=True,\n",
       "                                                token_pattern='\\\\w{1,}'))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {'bukan', 'kan', 'tampak', 'bila', 'tandas', 'terlihat', 'jangan', 'apalagi', 'termasuk', 'diibaratkan', 'sesudahnya', 'bersama', 'selalu', 'tersampaikan', 'tentunya', 'diperbuatnya', 'para', 'lah', 'tahu', 'keinginan', 'sepantasnyalah', 'pasti', 'memastikan', 'bawah', 'teringat', 'sudahkah', 'kelima', 'tutur', 'mengibaratkannya', 'memungkinkan', 'dimaksudkan', 'disinilah', 'sejenak', 'mengatakan', 'seolah-olah', 'tentu', 'bekerja', 'mirip', 'menanyai', 'walaupun', 'seringnya', 'bahwa', 'kembali', 'setempat', 'bagaikan', 'nyatanya', 'diminta', 'sekiranya', 'kapan', 'ketika', 'mana', 'itulah', 'diperlukannya', 'berturut', 'kesampaian', 'bolehkah', 'ujarnya', 'kiranya', 'disebutkannya', 'sela', 'tiba-tiba', 'entahlah', 'siap', 'kebetulan', 'sekurangnya', 'tadinya', 'sesampai', 'menanyakan', 'padahal', 'tentang', 'mengetahui', 'secara', 'sana', 'disampaikan', 'menegaskan', 'atas', 'setidak-tidaknya', 'sepanjang', 'meyakinkan', 'sesuatu', 'artinya', 'dibuatnya', 'sekadarnya', 'kemungkinan', 'meyakini', 'bertutur', 'bersiap-siap', 'menaiki', 'belakangan', 'hanyalah', 'menuturkan', 'balik', 'mengucapkannya', 'seperti', 'mempergunakan', 'benarkah', 'amat', 'seolah', 'dua', 'mendatangi', 'sebaik-baiknya', 'makin', 'berkata', 'dilihat', 'betulkah', 'apakah', 'ini', 'mempersiapkan', 'mampu', 'sinilah', 'kamulah', 'segalanya', 'maupun', 'ataupun', 'beginilah', 'kamu', 'masalah', 'selama-lamanya', 'berarti', 'diantara', 'dituturkan', 'tandasnya', 'menurut', 'bahwasanya', 'tidaklah', 'sampaikan', 'kami', 'diinginkan', 'sebuah', 'ditandaskan', 'ucap', 'saja', 'perlunya', 'bermacam', 'terdahulu', 'ungkap', 'semasih', 'wah', 'ditanyai', 'apa', 'dimulainya', 'sebenarnya', 'didapat', 'sesudah', 'lebih', 'sedikitnya', 'antaranya', 'ternyata', 'ingin', 'kepada', 'dalam', 'rupanya', 'sebab', 'hal', 'dijelaskan', 'biasanya', 'ditambahkan', 'demikianlah', 'bersama-sama', 'haruslah', 'jelaskan', 'lain', 'kemungkinannya', 'anda', 'dipersoalkan', 'mengingat', 'terkira', 'tambah', 'jelas', 'mulai', 'melakukan', 'ditegaskan', 'sesaat', 'sesegera', 'tinggi', 'bakal', 'rasanya', 'melihat', 'mengapa', 'kepadanya', 'kita', 'sebutnya', 'sehingga', 'berapakah', 'kenapa', 'memulai', 'tempat', 'jelasnya', 'pantas', 'sebaiknya', 'semampu', 'seseorang', 'ibarat', 'agar', 'keadaan', 'dimintai', 'ditujukan', 'setibanya', 'waktunya', 'kamilah', 'dialah', 'seluruhnya', 'memperbuat', 'guna', 'pihak', 'supaya', 'didatangkan', 'karenanya', 'diketahui', 'berawal', 'ingat', 'lama', 'meskipun', 'cukup', 'inikah', 'menyangkut', 'sebetulnya', 'dimaksud', 'berujar', 'kecil', 'tegasnya', 'tengah', 'setiba', 'terasa', 'sebabnya', 'teringat-ingat', 'baik', 'terbanyak', 'menunjuknya', 'tapi', 'dengan', 'betul', 'andalah', 'yakni', 'sekali', 'seterusnya', 'keduanya', 'jadi', 'panjang', 'bukanlah', 'diibaratkannya', 'jadilah', 'menyatakan', 'siapakah', 'tanya', 'semata-mata', 'begitupun', 'dimulailah', 'kalian', 'sekadar', 'sebelumnya', 'kalaupun', 'jika', 'siapa', 'bagian', 'melainkan', 'ingat-ingat', 'sejak', 'amatlah', 'tahun', 'umum', 'yaitu', 'diperkirakan', 'berapalah', 'ibaratnya', 'hendaklah', 'dirinya', 'sempat', 'justru', 'bilakah', 'selamanya', 'pastilah', 'jawab', 'rata', 'diperbuat', 'suatu', 'meski', 'sesama', 'berakhir', 'soalnya', 'lalu', 'memperlihatkan', 'persoalan', 'enggak', 'mempersoalkan', 'mengira', 'sesuatunya', 'bermacam-macam', 'menunjuki', 'punya', 'mereka', 'inginkah', 'dikerjakan', 'masing', 'gunakan', 'membuat', 'terhadapnya', 'dikatakan', 'cukupkah', 'sebisanya', 'bulan', 'kemudian', 'dimaksudkannya', 'terdiri', 'keseluruhan', 'bersiap', 'sewaktu', 'demikian', 'memisalkan', 'sebagai', 'berkenaan', 'ialah', 'keseluruhannya', 'semaunya', 'bisa', 'diberikan', 'tuturnya', 'ditanya', 'diantaranya', 'dijelaskannya', 'lainnya', 'kapankah', 'menyeluruh', 'berikut', 'begitu', 'mulanya', 'merasa', 'kira-kira', 'sedemikian', 'terakhir', 'terjadinya', 'nyaris', 'sedangkan', 'berapa', 'pula', 'adapun', 'sudah', 'sebagian', 'kurang', 'seorang', 'dimaksudnya', 'dari', 'seharusnya', 'diri', 'menambahkan', 'dilalui', 'wong', 'menjawab', 'mula', 'hingga', 'lagian', 'sekitar', 'lanjutnya', 'tertuju', 'melalui', 'pun', 'disini', 'sedikit', 'mengatakannya', 'menunjuk', 'merekalah', 'mempunyai', 'malah', 'sama-sama', 'misalkan', 'pertama-tama', 'terutama', 'janganlah', 'menyampaikan', 'sangat', 'dikarenakan', 'katakan', 'kala', 'awalnya', 'memerlukan', 'sebut', 'menyebutkan', 'sebagaimana', 'dimisalkan', 'manalagi', 'bukankah', 'kira', 'agak', 'dipastikan', 'bermula', 'macam', 'semacam', 'mengakhiri', 'perlu', 'begitukah', 'diberikannya', 'diucapkannya', 'mendapat', 'dipertanyakan', 'dikatakannya', 'namun', 'ibaratkan', 'sejauh', 'sekurang-kurangnya', 'sedang', 'belakang', 'minta', 'sendiri', 'sepertinya', 'sepihak', 'antara', 'inginkan', 'tidakkah', 'saling', 'kasus', 'keterlaluan', 'itu', 'mau', 'luar', 'memperkirakan', 'dan', 'dimungkinkan', 'diperlukan', 'tiba', 'naik', 'ikut', 'berakhirlah', 'berikan', 'saat', 'tanyanya', 'katakanlah', 'dahulu', 'tepat', 'nah', 'sejumlah', 'walau', 'sekaligus', 'datang', 'apaan', 'sendirinya', 'bung', 'entah', 'oleh', 'segala', 'mulailah', 'ditunjuki', 'rasa', 'serta', 'agaknya', 'hendaknya', 'dipunyai', 'beginian', 'berdatangan', 'semata', 'tiap', 'ke', 'bisakah', 'mendatang', 'berupa', 'juga', 'jawaban', 'berikutnya', 'dilakukan', 'sebegitu', 'dulu', 'waduh', 'dapat', 'sudahlah', 'merupakan', 'demi', 'ia', 'sekalian', 'telah', 'disebutkan', 'perlukah', 'hampir', 'diucapkan', 'sebesar', 'semisalnya', 'memberikan', 'berapapun', 'selain', 'mengucapkan', 'setelah', 'baru', 'selaku', 'beberapa', 'karena', 'sebaik', 'sebegini', 'ada', 'setidaknya', 'berkehendak', 'seperlunya', 'menghendaki', 'hendak', 'ungkapnya', 'kelihatan', 'keluar', 'pihaknya', 'sendirian', 'jumlah', 'seenaknya', 'menanti', 'terlalu', 'mungkinkah', 'ujar', 'diingat', 'cuma', 'sampai-sampai', 'berjumlah', 'terdapat', 'akhiri', 'olehnya', 'apabila', 'jangankan', 'menggunakan', 'dituturkannya', 'kelihatannya', 'kitalah', 'meminta', 'melihatnya', 'kok', 'benarlah', 'berlangsung', 'diketahuinya', 'menjadi', 'secukupnya', 'semua', 'padanya', 'menanya', 'ataukah', 'bakalan', 'berada', 'besar', 'mengungkapkan', 'cukuplah', 'menandaskan', 'hari', 'dia', 'masalahnya', 'jauh', 'semampunya', 'seusai', 'akankah', 'pentingnya', 'bermaksud', 'selama', 'buat', 'mendapatkan', 'berlalu', 'depan', 'ditunjukkannya', 'khususnya', 'sepantasnya', 'umumnya', 'mengerjakan', 'sebaliknya', 'sajalah', 'begini', 'memberi', 'kini', 'setinggi', 'tiga', 'lamanya', 'berbagai', 'inilah', 'penting', 'pak', 'pertanyaan', 'memintakan', 'mengenai', 'tidak', 'biasa', 'dipergunakan', 'lagi', 'pertanyakan', 'percuma', 'tersebut', 'bapak', 'berakhirnya', 'kalau', 'turut', 'dibuat', 'mempertanyakan', 'beri', 'mendatangkan', 'bagaimanapun', 'dijawab', 'bolehlah', 'sampai', 'ucapnya', 'menginginkan', 'misal', 'ditanyakan', 'hanya', 'masih', 'saatnya', 'pukul', 'akhirnya', 'diakhirinya', 'masa', 'saya', 'terjadilah', 'se', 'usai', 'sebelum', 'diakhiri', 'usah', 'manakala', 'itukah', 'sebutlah', 'dini', 'lima', 'wahai', 'begitulah', 'adalah', 'benar', 'yakin', 'caranya', 'segera', 'asal', 'diungkapkan', 'dimulai', 'seluruh', 'jumlahnya', 'enggaknya', 'banyak', 'berkeinginan', 'bahkan', 'kalaulah', 'memang', 'aku', 'semula', 'beginikah', 'kelamaan', 'seingat', 'toh', 'mengibaratkan', 'menjelaskan', 'terus', 'tanyakan', 'setiap', 'bertanya-tanya', 'sekitarnya', 'sayalah', 'akulah', 'ditunjuknya', 'kapanpun', 'sekecil', 'seberapa', 'tentulah', 'semakin', 'paling', 'pernah', 'soal', 'berturut-turut', 'digunakan', 'terjadi', 'tersebutlah', 'satu', 'sama', 'sekarang', 'bagai', 'katanya', 'ditunjukkan', 'jawabnya', 'pada', 'bertanya', 'menanti-nanti', 'malahan', 'jikalau', 'sekali-kali', 'nantinya', 'mengingatkan', 'tak', 'tegas', 'dekat', 'disebut', 'belum', 'misalnya', 'semasa', 'adanya', 'daripada', 'tadi', 'diingatkan', 'tampaknya', 'tetapi', 'diperlihatkan', 'akan', 'empat', 'sini', 'terlebih', 'setengah', 'tunjuk', 'bukannya', 'cara', 'kinilah', 'mampukah', 'tambahnya', 'tanpa', 'harusnya', 'makanya', 'sekalipun', 'serupa', 'sebagainya', 'dong', 'menuju', 'bagaimanakah', 'menyiapkan', 'belumlah', 'tetap', 'atau', 'sangatlah', 'jadinya', 'akhir', 'antar', 'menantikan', 'sebanyak', 'semuanya', 'siapapun', 'untuk', 'tertentu', 'diberi', 'dikira', 'lanjut', 'memihak', 'bagaimana', 'ibu', 'asalkan', 'sesekali', 'maka', 'berlainan', 'semisal', 'yang', 'awal', 'apatah', 'menunjukkan', 'per', 'lewat', 'sementara', 'berlebihan', 'ditunjuk', 'kedua', 'mungkin', 'sering', 'jelaslah', 'selanjutnya', 'waktu', 'masihkah', 'bagi', 'harus', 'pertama', 'berkali-kali', 'seketika', 'kata', 'sambil', 'di', 'terhadap', 'nanti', 'masing-masing', 'boleh'} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32me:\\!!PYTHON2023\\github-twitter-pilpres2024\\lexicon\\test_sentiment.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%21%21PYTHON2023/github-twitter-pilpres2024/lexicon/test_sentiment.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Fit my vectorizer on the entire dataset instead of the training rows\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%21%21PYTHON2023/github-twitter-pilpres2024/lexicon/test_sentiment.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#Score improved by .0001\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%21%21PYTHON2023/github-twitter-pilpres2024/lexicon/test_sentiment.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# df.to_dict\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%21%21PYTHON2023/github-twitter-pilpres2024/lexicon/test_sentiment.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m vectorizer\u001b[39m.\u001b[39;49mfit(df\u001b[39m.\u001b[39;49mto_dict())\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\pipeline.py:1240\u001b[0m, in \u001b[0;36mFeatureUnion.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m   1222\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m \n\u001b[0;32m   1224\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[39m        FeatureUnion class instance.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1240\u001b[0m     transformers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parallel_func(X, y, fit_params, _fit_one)\n\u001b[0;32m   1241\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m transformers:\n\u001b[0;32m   1242\u001b[0m         \u001b[39m# All transformers are None\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\pipeline.py:1291\u001b[0m, in \u001b[0;36mFeatureUnion._parallel_func\u001b[1;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformer_weights()\n\u001b[0;32m   1289\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter())\n\u001b[1;32m-> 1291\u001b[0m \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m   1292\u001b[0m     delayed(func)(\n\u001b[0;32m   1293\u001b[0m         transformer,\n\u001b[0;32m   1294\u001b[0m         X,\n\u001b[0;32m   1295\u001b[0m         y,\n\u001b[0;32m   1296\u001b[0m         weight,\n\u001b[0;32m   1297\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mFeatureUnion\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1298\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m   1299\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params,\n\u001b[0;32m   1300\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx, (name, transformer, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1302\u001b[0m )\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\pipeline.py:971\u001b[0m, in \u001b[0;36m_fit_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39mFits ``transformer`` to ``X`` and ``y``.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[0;32m   1141\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1142\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    631\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    640\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    641\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    642\u001b[0m     )\n",
      "File \u001b[1;32mc:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[1;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got {'bukan', 'kan', 'tampak', 'bila', 'tandas', 'terlihat', 'jangan', 'apalagi', 'termasuk', 'diibaratkan', 'sesudahnya', 'bersama', 'selalu', 'tersampaikan', 'tentunya', 'diperbuatnya', 'para', 'lah', 'tahu', 'keinginan', 'sepantasnyalah', 'pasti', 'memastikan', 'bawah', 'teringat', 'sudahkah', 'kelima', 'tutur', 'mengibaratkannya', 'memungkinkan', 'dimaksudkan', 'disinilah', 'sejenak', 'mengatakan', 'seolah-olah', 'tentu', 'bekerja', 'mirip', 'menanyai', 'walaupun', 'seringnya', 'bahwa', 'kembali', 'setempat', 'bagaikan', 'nyatanya', 'diminta', 'sekiranya', 'kapan', 'ketika', 'mana', 'itulah', 'diperlukannya', 'berturut', 'kesampaian', 'bolehkah', 'ujarnya', 'kiranya', 'disebutkannya', 'sela', 'tiba-tiba', 'entahlah', 'siap', 'kebetulan', 'sekurangnya', 'tadinya', 'sesampai', 'menanyakan', 'padahal', 'tentang', 'mengetahui', 'secara', 'sana', 'disampaikan', 'menegaskan', 'atas', 'setidak-tidaknya', 'sepanjang', 'meyakinkan', 'sesuatu', 'artinya', 'dibuatnya', 'sekadarnya', 'kemungkinan', 'meyakini', 'bertutur', 'bersiap-siap', 'menaiki', 'belakangan', 'hanyalah', 'menuturkan', 'balik', 'mengucapkannya', 'seperti', 'mempergunakan', 'benarkah', 'amat', 'seolah', 'dua', 'mendatangi', 'sebaik-baiknya', 'makin', 'berkata', 'dilihat', 'betulkah', 'apakah', 'ini', 'mempersiapkan', 'mampu', 'sinilah', 'kamulah', 'segalanya', 'maupun', 'ataupun', 'beginilah', 'kamu', 'masalah', 'selama-lamanya', 'berarti', 'diantara', 'dituturkan', 'tandasnya', 'menurut', 'bahwasanya', 'tidaklah', 'sampaikan', 'kami', 'diinginkan', 'sebuah', 'ditandaskan', 'ucap', 'saja', 'perlunya', 'bermacam', 'terdahulu', 'ungkap', 'semasih', 'wah', 'ditanyai', 'apa', 'dimulainya', 'sebenarnya', 'didapat', 'sesudah', 'lebih', 'sedikitnya', 'antaranya', 'ternyata', 'ingin', 'kepada', 'dalam', 'rupanya', 'sebab', 'hal', 'dijelaskan', 'biasanya', 'ditambahkan', 'demikianlah', 'bersama-sama', 'haruslah', 'jelaskan', 'lain', 'kemungkinannya', 'anda', 'dipersoalkan', 'mengingat', 'terkira', 'tambah', 'jelas', 'mulai', 'melakukan', 'ditegaskan', 'sesaat', 'sesegera', 'tinggi', 'bakal', 'rasanya', 'melihat', 'mengapa', 'kepadanya', 'kita', 'sebutnya', 'sehingga', 'berapakah', 'kenapa', 'memulai', 'tempat', 'jelasnya', 'pantas', 'sebaiknya', 'semampu', 'seseorang', 'ibarat', 'agar', 'keadaan', 'dimintai', 'ditujukan', 'setibanya', 'waktunya', 'kamilah', 'dialah', 'seluruhnya', 'memperbuat', 'guna', 'pihak', 'supaya', 'didatangkan', 'karenanya', 'diketahui', 'berawal', 'ingat', 'lama', 'meskipun', 'cukup', 'inikah', 'menyangkut', 'sebetulnya', 'dimaksud', 'berujar', 'kecil', 'tegasnya', 'tengah', 'setiba', 'terasa', 'sebabnya', 'teringat-ingat', 'baik', 'terbanyak', 'menunjuknya', 'tapi', 'dengan', 'betul', 'andalah', 'yakni', 'sekali', 'seterusnya', 'keduanya', 'jadi', 'panjang', 'bukanlah', 'diibaratkannya', 'jadilah', 'menyatakan', 'siapakah', 'tanya', 'semata-mata', 'begitupun', 'dimulailah', 'kalian', 'sekadar', 'sebelumnya', 'kalaupun', 'jika', 'siapa', 'bagian', 'melainkan', 'ingat-ingat', 'sejak', 'amatlah', 'tahun', 'umum', 'yaitu', 'diperkirakan', 'berapalah', 'ibaratnya', 'hendaklah', 'dirinya', 'sempat', 'justru', 'bilakah', 'selamanya', 'pastilah', 'jawab', 'rata', 'diperbuat', 'suatu', 'meski', 'sesama', 'berakhir', 'soalnya', 'lalu', 'memperlihatkan', 'persoalan', 'enggak', 'mempersoalkan', 'mengira', 'sesuatunya', 'bermacam-macam', 'menunjuki', 'punya', 'mereka', 'inginkah', 'dikerjakan', 'masing', 'gunakan', 'membuat', 'terhadapnya', 'dikatakan', 'cukupkah', 'sebisanya', 'bulan', 'kemudian', 'dimaksudkannya', 'terdiri', 'keseluruhan', 'bersiap', 'sewaktu', 'demikian', 'memisalkan', 'sebagai', 'berkenaan', 'ialah', 'keseluruhannya', 'semaunya', 'bisa', 'diberikan', 'tuturnya', 'ditanya', 'diantaranya', 'dijelaskannya', 'lainnya', 'kapankah', 'menyeluruh', 'berikut', 'begitu', 'mulanya', 'merasa', 'kira-kira', 'sedemikian', 'terakhir', 'terjadinya', 'nyaris', 'sedangkan', 'berapa', 'pula', 'adapun', 'sudah', 'sebagian', 'kurang', 'seorang', 'dimaksudnya', 'dari', 'seharusnya', 'diri', 'menambahkan', 'dilalui', 'wong', 'menjawab', 'mula', 'hingga', 'lagian', 'sekitar', 'lanjutnya', 'tertuju', 'melalui', 'pun', 'disini', 'sedikit', 'mengatakannya', 'menunjuk', 'merekalah', 'mempunyai', 'malah', 'sama-sama', 'misalkan', 'pertama-tama', 'terutama', 'janganlah', 'menyampaikan', 'sangat', 'dikarenakan', 'katakan', 'kala', 'awalnya', 'memerlukan', 'sebut', 'menyebutkan', 'sebagaimana', 'dimisalkan', 'manalagi', 'bukankah', 'kira', 'agak', 'dipastikan', 'bermula', 'macam', 'semacam', 'mengakhiri', 'perlu', 'begitukah', 'diberikannya', 'diucapkannya', 'mendapat', 'dipertanyakan', 'dikatakannya', 'namun', 'ibaratkan', 'sejauh', 'sekurang-kurangnya', 'sedang', 'belakang', 'minta', 'sendiri', 'sepertinya', 'sepihak', 'antara', 'inginkan', 'tidakkah', 'saling', 'kasus', 'keterlaluan', 'itu', 'mau', 'luar', 'memperkirakan', 'dan', 'dimungkinkan', 'diperlukan', 'tiba', 'naik', 'ikut', 'berakhirlah', 'berikan', 'saat', 'tanyanya', 'katakanlah', 'dahulu', 'tepat', 'nah', 'sejumlah', 'walau', 'sekaligus', 'datang', 'apaan', 'sendirinya', 'bung', 'entah', 'oleh', 'segala', 'mulailah', 'ditunjuki', 'rasa', 'serta', 'agaknya', 'hendaknya', 'dipunyai', 'beginian', 'berdatangan', 'semata', 'tiap', 'ke', 'bisakah', 'mendatang', 'berupa', 'juga', 'jawaban', 'berikutnya', 'dilakukan', 'sebegitu', 'dulu', 'waduh', 'dapat', 'sudahlah', 'merupakan', 'demi', 'ia', 'sekalian', 'telah', 'disebutkan', 'perlukah', 'hampir', 'diucapkan', 'sebesar', 'semisalnya', 'memberikan', 'berapapun', 'selain', 'mengucapkan', 'setelah', 'baru', 'selaku', 'beberapa', 'karena', 'sebaik', 'sebegini', 'ada', 'setidaknya', 'berkehendak', 'seperlunya', 'menghendaki', 'hendak', 'ungkapnya', 'kelihatan', 'keluar', 'pihaknya', 'sendirian', 'jumlah', 'seenaknya', 'menanti', 'terlalu', 'mungkinkah', 'ujar', 'diingat', 'cuma', 'sampai-sampai', 'berjumlah', 'terdapat', 'akhiri', 'olehnya', 'apabila', 'jangankan', 'menggunakan', 'dituturkannya', 'kelihatannya', 'kitalah', 'meminta', 'melihatnya', 'kok', 'benarlah', 'berlangsung', 'diketahuinya', 'menjadi', 'secukupnya', 'semua', 'padanya', 'menanya', 'ataukah', 'bakalan', 'berada', 'besar', 'mengungkapkan', 'cukuplah', 'menandaskan', 'hari', 'dia', 'masalahnya', 'jauh', 'semampunya', 'seusai', 'akankah', 'pentingnya', 'bermaksud', 'selama', 'buat', 'mendapatkan', 'berlalu', 'depan', 'ditunjukkannya', 'khususnya', 'sepantasnya', 'umumnya', 'mengerjakan', 'sebaliknya', 'sajalah', 'begini', 'memberi', 'kini', 'setinggi', 'tiga', 'lamanya', 'berbagai', 'inilah', 'penting', 'pak', 'pertanyaan', 'memintakan', 'mengenai', 'tidak', 'biasa', 'dipergunakan', 'lagi', 'pertanyakan', 'percuma', 'tersebut', 'bapak', 'berakhirnya', 'kalau', 'turut', 'dibuat', 'mempertanyakan', 'beri', 'mendatangkan', 'bagaimanapun', 'dijawab', 'bolehlah', 'sampai', 'ucapnya', 'menginginkan', 'misal', 'ditanyakan', 'hanya', 'masih', 'saatnya', 'pukul', 'akhirnya', 'diakhirinya', 'masa', 'saya', 'terjadilah', 'se', 'usai', 'sebelum', 'diakhiri', 'usah', 'manakala', 'itukah', 'sebutlah', 'dini', 'lima', 'wahai', 'begitulah', 'adalah', 'benar', 'yakin', 'caranya', 'segera', 'asal', 'diungkapkan', 'dimulai', 'seluruh', 'jumlahnya', 'enggaknya', 'banyak', 'berkeinginan', 'bahkan', 'kalaulah', 'memang', 'aku', 'semula', 'beginikah', 'kelamaan', 'seingat', 'toh', 'mengibaratkan', 'menjelaskan', 'terus', 'tanyakan', 'setiap', 'bertanya-tanya', 'sekitarnya', 'sayalah', 'akulah', 'ditunjuknya', 'kapanpun', 'sekecil', 'seberapa', 'tentulah', 'semakin', 'paling', 'pernah', 'soal', 'berturut-turut', 'digunakan', 'terjadi', 'tersebutlah', 'satu', 'sama', 'sekarang', 'bagai', 'katanya', 'ditunjukkan', 'jawabnya', 'pada', 'bertanya', 'menanti-nanti', 'malahan', 'jikalau', 'sekali-kali', 'nantinya', 'mengingatkan', 'tak', 'tegas', 'dekat', 'disebut', 'belum', 'misalnya', 'semasa', 'adanya', 'daripada', 'tadi', 'diingatkan', 'tampaknya', 'tetapi', 'diperlihatkan', 'akan', 'empat', 'sini', 'terlebih', 'setengah', 'tunjuk', 'bukannya', 'cara', 'kinilah', 'mampukah', 'tambahnya', 'tanpa', 'harusnya', 'makanya', 'sekalipun', 'serupa', 'sebagainya', 'dong', 'menuju', 'bagaimanakah', 'menyiapkan', 'belumlah', 'tetap', 'atau', 'sangatlah', 'jadinya', 'akhir', 'antar', 'menantikan', 'sebanyak', 'semuanya', 'siapapun', 'untuk', 'tertentu', 'diberi', 'dikira', 'lanjut', 'memihak', 'bagaimana', 'ibu', 'asalkan', 'sesekali', 'maka', 'berlainan', 'semisal', 'yang', 'awal', 'apatah', 'menunjukkan', 'per', 'lewat', 'sementara', 'berlebihan', 'ditunjuk', 'kedua', 'mungkin', 'sering', 'jelaslah', 'selanjutnya', 'waktu', 'masihkah', 'bagi', 'harus', 'pertama', 'berkali-kali', 'seketika', 'kata', 'sambil', 'di', 'terhadap', 'nanti', 'masing-masing', 'boleh'} instead."
     ]
    }
   ],
   "source": [
    "#Fit my vectorizer on the entire dataset instead of the training rows\n",
    "#Score improved by .0001\n",
    "# df.to_dict\n",
    "vectorizer.fit(df.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
