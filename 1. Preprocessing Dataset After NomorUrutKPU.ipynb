{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load necessary library and module\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text pre-processing to DataFrame\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "snowball = nltk.stem.SnowballStemmer('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StemmerFactory class\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "# stemming process\n",
    "# sentence = 'Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan'\n",
    "# output   = stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('dataset/dataset_after_nomorurut_23112023_alldataset.csv', encoding='ISO-8859-1')#'UTF-8') #'ISO-8859-1')\n",
    "# samples= pd.read_csv('hasil/samples.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7306 entries, 0 to 7305\n",
      "Data columns (total 26 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   7306 non-null   float64\n",
      " 1   likes                7306 non-null   int64  \n",
      " 2   quotes               7306 non-null   int64  \n",
      " 3   replies              7306 non-null   int64  \n",
      " 4   retweets             7306 non-null   int64  \n",
      " 5   searchQuery          7306 non-null   object \n",
      " 6   text                 7306 non-null   object \n",
      " 7   timestamp            7306 non-null   object \n",
      " 8   tanggal              7306 non-null   object \n",
      " 9   url                  7306 non-null   object \n",
      " 10  user/avatar          7306 non-null   object \n",
      " 11  user/description     5197 non-null   object \n",
      " 12  user/joinDate        7306 non-null   object \n",
      " 13  user_location        3472 non-null   object \n",
      " 14  user/totalFollowers  7306 non-null   int64  \n",
      " 15  user/totalFollowing  7306 non-null   int64  \n",
      " 16  user/totalLikes      7306 non-null   int64  \n",
      " 17  user/totalTweets     7306 non-null   int64  \n",
      " 18  user/url             7306 non-null   object \n",
      " 19  user/userFullName    7182 non-null   object \n",
      " 20  user/username        7306 non-null   object \n",
      " 21  user/verified        7306 non-null   bool   \n",
      " 22  user/website         1521 non-null   object \n",
      " 23  username             2602 non-null   object \n",
      " 24  verified             7306 non-null   bool   \n",
      " 25  dataset              7306 non-null   object \n",
      "dtypes: bool(2), float64(1), int64(8), object(15)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_object = datetime.strptime(dataset['tanggal'], '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank = bank[['content', 'score']]\n",
    "# samples=dataset[['tanggal','text']].iloc[1:10]\n",
    "samples=dataset[['tanggal','text','likes','replies','quotes','retweets','searchQuery','timestamp','user_location','dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7306 entries, 0 to 7305\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tanggal        7306 non-null   object\n",
      " 1   text           7306 non-null   object\n",
      " 2   likes          7306 non-null   int64 \n",
      " 3   replies        7306 non-null   int64 \n",
      " 4   quotes         7306 non-null   int64 \n",
      " 5   retweets       7306 non-null   int64 \n",
      " 6   searchQuery    7306 non-null   object\n",
      " 7   timestamp      7306 non-null   object\n",
      " 8   user_location  3472 non-null   object\n",
      " 9   dataset        7306 non-null   object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 570.9+ KB\n"
     ]
    }
   ],
   "source": [
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase all text\n",
    "samples['text_lower']=(dataset['text'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanggal                                                 11/20/2023\n",
      "text             Cerita awal mula Pak Prabowo bertemu seorang p...\n",
      "likes                                                            0\n",
      "replies                                                          0\n",
      "quotes                                                           0\n",
      "retweets                                                         0\n",
      "searchQuery                                                   #KIM\n",
      "timestamp                                 2023-11-20T16:51:00.000Z\n",
      "user_location                                                  NaN\n",
      "dataset                                              prabowogibran\n",
      "text_lower       cerita awal mula pak prabowo bertemu seorang p...\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(samples.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2324 entries, 0 to 2323\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tanggal        2324 non-null   object\n",
      " 1   text           2324 non-null   object\n",
      " 2   likes          2324 non-null   int64 \n",
      " 3   replies        2324 non-null   int64 \n",
      " 4   quotes         2324 non-null   int64 \n",
      " 5   retweets       2324 non-null   int64 \n",
      " 6   searchQuery    2324 non-null   object\n",
      " 7   timestamp      2324 non-null   object\n",
      " 8   user_location  1223 non-null   object\n",
      " 9   text_lower     2324 non-null   object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 181.7+ KB\n"
     ]
    }
   ],
   "source": [
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(stemming(samples.text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>quotes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_location</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/14/2023</td>\n",
       "      <td>Sah, Pasangan Prabowo-Gibran dapat Nomor Urut ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-14T15:49:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>sah, pasangan prabowo-gibran dapat nomor urut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/15/2023</td>\n",
       "      <td>#nomor 1 Amin menang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-15T12:32:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>#nomor 1 amin menang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/20/2023</td>\n",
       "      <td>Pak Prabowo mengangkat anak penerbang tucano y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#KIM</td>\n",
       "      <td>2023-11-20T17:30:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>pak prabowo mengangkat anak penerbang tucano y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/20/2023</td>\n",
       "      <td>Unboxing Prabowo; Cerita sejarah, deklarasi bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#KIM</td>\n",
       "      <td>2023-11-20T17:25:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>unboxing prabowo; cerita sejarah, deklarasi bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/14/2023</td>\n",
       "      <td>#Nomor 1\\n\\nIndonesia beradab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-14T14:55:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>#nomor 1\\n\\nindonesia beradab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tanggal                                               text  likes  \\\n",
       "0  11/14/2023  Sah, Pasangan Prabowo-Gibran dapat Nomor Urut ...      0   \n",
       "1  11/15/2023                               #nomor 1 Amin menang      0   \n",
       "2  11/20/2023  Pak Prabowo mengangkat anak penerbang tucano y...      0   \n",
       "3  11/20/2023  Unboxing Prabowo; Cerita sejarah, deklarasi bu...      1   \n",
       "4  11/14/2023                      #Nomor 1\\n\\nIndonesia beradab      0   \n",
       "\n",
       "   replies  quotes  retweets searchQuery                 timestamp  \\\n",
       "0        0       0         0      #nomor  2023-11-14T15:49:00.000Z   \n",
       "1        0       0         0      #nomor  2023-11-15T12:32:00.000Z   \n",
       "2        0       0         0        #KIM  2023-11-20T17:30:00.000Z   \n",
       "3        0       0         0        #KIM  2023-11-20T17:25:00.000Z   \n",
       "4        0       0         0      #nomor  2023-11-14T14:55:00.000Z   \n",
       "\n",
       "  user_location        dataset  \\\n",
       "0           NaN  prabowogibran   \n",
       "1           NaN  prabowogibran   \n",
       "2           NaN  prabowogibran   \n",
       "3           NaN  prabowogibran   \n",
       "4           NaN  prabowogibran   \n",
       "\n",
       "                                          text_lower  \n",
       "0  sah, pasangan prabowo-gibran dapat nomor urut ...  \n",
       "1                               #nomor 1 amin menang  \n",
       "2  pak prabowo mengangkat anak penerbang tucano y...  \n",
       "3  unboxing prabowo; cerita sejarah, deklarasi bu...  \n",
       "4                      #nomor 1\\n\\nindonesia beradab  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samplex= pd.read_csv('hasil/samples.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_id = stopwords.words('indonesian')\n",
    "len(stopwords_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara', 'antaranya', 'apa', 'apaan', 'apabila', 'apakah', 'apalagi', 'apatah', 'artinya', 'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal', 'awalnya', 'bagai', 'bagaikan', 'bagaimana', 'bagaimanakah', 'bagaimanapun', 'bagi', 'bagian', 'bahkan', 'bahwa', 'bahwasanya', 'baik', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah', 'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah', 'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah', 'benar', 'benarkah', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya', 'berapa', 'berapakah', 'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'beri', 'berikan', 'berikut', 'berikutnya', 'berjumlah', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan', 'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam', 'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap', 'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar', 'berupa', 'besar', 'betul', 'betulkah', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'bisakah', 'boleh', 'bolehkah', 'bolehlah', 'buat', 'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'cara', 'caranya', 'cukup', 'cukupkah', 'cukuplah', 'cuma', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi', 'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya', 'dialah', 'diantara', 'diantaranya', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat', 'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan', 'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan', 'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan', 'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah', 'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan', 'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan', 'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebut', 'disebutkan', 'disebutkannya', 'disini', 'disinilah', 'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk', 'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan', 'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'empat', 'enggak', 'enggaknya', 'entah', 'entahlah', 'guna', 'gunakan', 'hal', 'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'hendak', 'hendaklah', 'hendaknya', 'hingga', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut', 'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban', 'jawabnya', 'jelas', 'jelaskan', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kalian', 'kami', 'kamilah', 'kamu', 'kamulah', 'kan', 'kapan', 'kapankah', 'kapanpun', 'karena', 'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya', 'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan', 'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kenapa', 'kepada', 'kepadanya', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'lalu', 'lama', 'lamanya', 'lanjut', 'lanjutnya', 'lebih', 'lewat', 'lima', 'luar', 'macam', 'maka', 'makanya', 'makin', 'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya', 'masih', 'masihkah', 'masing', 'masing-masing', 'mau', 'maupun', 'melainkan', 'melakukan', 'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat', 'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan', 'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai', 'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti', 'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi', 'mendatangkan', 'menegaskan', 'mengakhiri', 'mengapa', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan', 'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan', 'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab', 'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjukkan', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan', 'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah', 'merupakan', 'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'nah', 'naik', 'namun', 'nanti', 'nantinya', 'nyaris', 'nyatanya', 'oleh', 'olehnya', 'pada', 'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting', 'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama', 'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'rasa', 'rasanya', 'rata', 'rupanya', 'saat', 'saatnya', 'saja', 'sajalah', 'saling', 'sama', 'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian', 'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum', 'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', 'sebut', 'sebutlah', 'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya', 'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah', 'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekarang', 'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela', 'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya', 'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya', 'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian', 'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya', 'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai', 'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat', 'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai', 'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', 'sudahkah', 'sudahlah', 'supaya', 'tadi', 'tadinya', 'tahu', 'tahun', 'tak', 'tambah', 'tambahnya', 'tampak', 'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya', 'telah', 'tempat', 'tengah', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak', 'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi', 'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan', 'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba', 'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'tinggi', 'toh', 'tunjuk', 'turut', 'tutur', 'tuturnya', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umum', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'waduh', 'wah', 'wahai', 'waktu', 'waktunya', 'walau', 'walaupun', 'wong', 'yaitu', 'yakin', 'yakni', 'yang']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk langkah stopwords removal\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  clean_word = []\n",
    "  all_text = text.split()\n",
    "  for word in all_text:\n",
    "    if word not in stopwords_id:\n",
    "      clean_word.append(word)\n",
    "  return ' '.join(clean_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f43f6cecfcf4fe98ab44bc7297f8b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['stopwords'] = samples['text_lower'].progress_apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisasi Kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml): started\n",
      "  Building wheel for wget (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=9ff960d39acc32eabd596f6f50854a71dcc4832292680502b2140b25c4ca4ad4\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\8b\\f1\\7f\\5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dataset/normalisasi (1).csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download corpus singkatan\n",
    "# !pip install wget\n",
    "# import wget\n",
    "# wget.download('https://raw.githubusercontent.com/ksnugroho/klasifikasi-spam-sms/master/data/key_norm.csv','dataset/normalisasi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_norm = pd.read_csv('dataset/normalisasi.csv')\n",
    "\n",
    "# Buat fungsi untuk melakukan word normalization\n",
    "def normalisasi(text):\n",
    "  text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0] if (key_norm['singkat'] == word).any() else word for word in text.split()])\n",
    "  text = str.lower(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651c12fdd80a4c93ba2ae847cbb7a35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['norm_content'] = samples['stopwords'].progress_apply(lambda x: normalisasi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bad22092cc3421a8a9536a37a4aaa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['stem_content'] = samples['norm_content'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>quotes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_location</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>norm_content</th>\n",
       "      <th>stem_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/14/2023</td>\n",
       "      <td>Sah, Pasangan Prabowo-Gibran dapat Nomor Urut ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-14T15:49:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>sah, pasangan prabowo-gibran dapat nomor urut ...</td>\n",
       "      <td>sah, pasangan prabowo-gibran nomor urut 2 dite...</td>\n",
       "      <td>sah, pasangan prabowo-gibran nomor urut 2 dite...</td>\n",
       "      <td>sah pasang prabowo-gibran nomor urut 2 tetap k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/15/2023</td>\n",
       "      <td>#nomor 1 Amin menang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-15T12:32:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>#nomor 1 amin menang</td>\n",
       "      <td>#nomor 1 amin menang</td>\n",
       "      <td>#nomor 1 amin menang</td>\n",
       "      <td>nomor 1 amin menang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/20/2023</td>\n",
       "      <td>Pak Prabowo mengangkat anak penerbang tucano y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#KIM</td>\n",
       "      <td>2023-11-20T17:30:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>pak prabowo mengangkat anak penerbang tucano y...</td>\n",
       "      <td>prabowo mengangkat anak penerbang tucano gugur...</td>\n",
       "      <td>prabowo mengangkat anak penerbang tucano gugur...</td>\n",
       "      <td>prabowo angkat anak terbang tucano gugur anak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/20/2023</td>\n",
       "      <td>Unboxing Prabowo; Cerita sejarah, deklarasi bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#KIM</td>\n",
       "      <td>2023-11-20T17:25:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>unboxing prabowo; cerita sejarah, deklarasi bu...</td>\n",
       "      <td>unboxing prabowo; cerita sejarah, deklarasi bu...</td>\n",
       "      <td>unboxing prabowo; cerita sejarah, deklarasi bu...</td>\n",
       "      <td>unboxing prabowo cerita sejarah deklarasi budi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/14/2023</td>\n",
       "      <td>#Nomor 1\\n\\nIndonesia beradab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#nomor</td>\n",
       "      <td>2023-11-14T14:55:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prabowogibran</td>\n",
       "      <td>#nomor 1\\n\\nindonesia beradab</td>\n",
       "      <td>#nomor 1 indonesia beradab</td>\n",
       "      <td>#nomor 1 indonesia beradab</td>\n",
       "      <td>nomor 1 indonesia adab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tanggal                                               text  likes  \\\n",
       "0  11/14/2023  Sah, Pasangan Prabowo-Gibran dapat Nomor Urut ...      0   \n",
       "1  11/15/2023                               #nomor 1 Amin menang      0   \n",
       "2  11/20/2023  Pak Prabowo mengangkat anak penerbang tucano y...      0   \n",
       "3  11/20/2023  Unboxing Prabowo; Cerita sejarah, deklarasi bu...      1   \n",
       "4  11/14/2023                      #Nomor 1\\n\\nIndonesia beradab      0   \n",
       "\n",
       "   replies  quotes  retweets searchQuery                 timestamp  \\\n",
       "0        0       0         0      #nomor  2023-11-14T15:49:00.000Z   \n",
       "1        0       0         0      #nomor  2023-11-15T12:32:00.000Z   \n",
       "2        0       0         0        #KIM  2023-11-20T17:30:00.000Z   \n",
       "3        0       0         0        #KIM  2023-11-20T17:25:00.000Z   \n",
       "4        0       0         0      #nomor  2023-11-14T14:55:00.000Z   \n",
       "\n",
       "  user_location        dataset  \\\n",
       "0           NaN  prabowogibran   \n",
       "1           NaN  prabowogibran   \n",
       "2           NaN  prabowogibran   \n",
       "3           NaN  prabowogibran   \n",
       "4           NaN  prabowogibran   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  sah, pasangan prabowo-gibran dapat nomor urut ...   \n",
       "1                               #nomor 1 amin menang   \n",
       "2  pak prabowo mengangkat anak penerbang tucano y...   \n",
       "3  unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
       "4                      #nomor 1\\n\\nindonesia beradab   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  sah, pasangan prabowo-gibran nomor urut 2 dite...   \n",
       "1                               #nomor 1 amin menang   \n",
       "2  prabowo mengangkat anak penerbang tucano gugur...   \n",
       "3  unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
       "4                         #nomor 1 indonesia beradab   \n",
       "\n",
       "                                        norm_content  \\\n",
       "0  sah, pasangan prabowo-gibran nomor urut 2 dite...   \n",
       "1                               #nomor 1 amin menang   \n",
       "2  prabowo mengangkat anak penerbang tucano gugur...   \n",
       "3  unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
       "4                         #nomor 1 indonesia beradab   \n",
       "\n",
       "                                        stem_content  \n",
       "0  sah pasang prabowo-gibran nomor urut 2 tetap k...  \n",
       "1                                nomor 1 amin menang  \n",
       "2  prabowo angkat anak terbang tucano gugur anak ...  \n",
       "3  unboxing prabowo cerita sejarah deklarasi budi...  \n",
       "4                             nomor 1 indonesia adab  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>quotes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7306.000000</td>\n",
       "      <td>7306.000000</td>\n",
       "      <td>7306.000000</td>\n",
       "      <td>7306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.425267</td>\n",
       "      <td>17.613332</td>\n",
       "      <td>2.014645</td>\n",
       "      <td>26.717219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>570.088226</td>\n",
       "      <td>201.970256</td>\n",
       "      <td>19.295630</td>\n",
       "      <td>227.531628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18140.000000</td>\n",
       "      <td>5037.000000</td>\n",
       "      <td>691.000000</td>\n",
       "      <td>4678.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes      replies       quotes     retweets\n",
       "count   7306.000000  7306.000000  7306.000000  7306.000000\n",
       "mean      66.425267    17.613332     2.014645    26.717219\n",
       "std      570.088226   201.970256    19.295630   227.531628\n",
       "min        0.000000     0.000000     0.000000     0.000000\n",
       "25%        0.000000     0.000000     0.000000     0.000000\n",
       "50%        0.000000     0.000000     0.000000     0.000000\n",
       "75%        2.000000     1.000000     0.000000     0.000000\n",
       "max    18140.000000  5037.000000   691.000000  4678.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tanggal                                               text  likes  \\\n",
      "0     11/14/2023  Sah, Pasangan Prabowo-Gibran dapat Nomor Urut ...      0   \n",
      "1     11/15/2023                               #nomor 1 Amin menang      0   \n",
      "2     11/20/2023  Pak Prabowo mengangkat anak penerbang tucano y...      0   \n",
      "3     11/20/2023  Unboxing Prabowo; Cerita sejarah, deklarasi bu...      1   \n",
      "4     11/14/2023                      #Nomor 1\\n\\nIndonesia beradab      0   \n",
      "...          ...                                                ...    ...   \n",
      "7301  11/19/2023  Yuk dukung selalu nomor urut 3 jangan sampai s...      0   \n",
      "7302  11/20/2023  Sudah diingatkan beberapa kali oleh pak Ketum ...     13   \n",
      "7303  11/20/2023  Masa Tempo takut kalah kan bukan paslon tp maj...      0   \n",
      "7304  11/19/2023  Bersiaplah untuk sebuah era di mana ide-ide br...      0   \n",
      "7305  11/20/2023  Krna paslon islam maka himbauan nya secara isl...      0   \n",
      "\n",
      "      replies  quotes  retweets searchQuery                 timestamp  \\\n",
      "0           0       0         0      #nomor  2023-11-14T15:49:00.000Z   \n",
      "1           0       0         0      #nomor  2023-11-15T12:32:00.000Z   \n",
      "2           0       0         0        #KIM  2023-11-20T17:30:00.000Z   \n",
      "3           0       0         0        #KIM  2023-11-20T17:25:00.000Z   \n",
      "4           0       0         0      #nomor  2023-11-14T14:55:00.000Z   \n",
      "...       ...     ...       ...         ...                       ...   \n",
      "7301        0       0         0  nomor urut  2023-11-19T15:49:00.000Z   \n",
      "7302        2       0         4      paslon  2023-11-20T09:59:00.000Z   \n",
      "7303        1       0         0      paslon  2023-11-20T11:25:00.000Z   \n",
      "7304        0       0         0  nomor urut  2023-11-19T15:11:00.000Z   \n",
      "7305        0       0         0      paslon  2023-11-20T11:18:00.000Z   \n",
      "\n",
      "               user_location        dataset  \\\n",
      "0                        NaN  prabowogibran   \n",
      "1                        NaN  prabowogibran   \n",
      "2                        NaN  prabowogibran   \n",
      "3                        NaN  prabowogibran   \n",
      "4                        NaN  prabowogibran   \n",
      "...                      ...            ...   \n",
      "7301                     NaN   ganjarmahfud   \n",
      "7302  Jakarta Capital Region   ganjarmahfud   \n",
      "7303     Bandung, Jawa Barat   ganjarmahfud   \n",
      "7304                 Bandung   ganjarmahfud   \n",
      "7305                     NaN   ganjarmahfud   \n",
      "\n",
      "                                             text_lower  \\\n",
      "0     sah, pasangan prabowo-gibran dapat nomor urut ...   \n",
      "1                                  #nomor 1 amin menang   \n",
      "2     pak prabowo mengangkat anak penerbang tucano y...   \n",
      "3     unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
      "4                         #nomor 1\\n\\nindonesia beradab   \n",
      "...                                                 ...   \n",
      "7301  yuk dukung selalu nomor urut 3 jangan sampai s...   \n",
      "7302  sudah diingatkan beberapa kali oleh pak ketum ...   \n",
      "7303  masa tempo takut kalah kan bukan paslon tp maj...   \n",
      "7304  bersiaplah untuk sebuah era di mana ide-ide br...   \n",
      "7305  krna paslon islam maka himbauan nya secara isl...   \n",
      "\n",
      "                                              stopwords  \\\n",
      "0     sah, pasangan prabowo-gibran nomor urut 2 dite...   \n",
      "1                                  #nomor 1 amin menang   \n",
      "2     prabowo mengangkat anak penerbang tucano gugur...   \n",
      "3     unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
      "4                            #nomor 1 indonesia beradab   \n",
      "...                                                 ...   \n",
      "7301           yuk dukung nomor urut 3 salah pilih yaaa   \n",
      "7302  kali ketum @partaisocmed merusak suara ulah pe...   \n",
      "7303         tempo takut kalah paslon tp majalah berita   \n",
      "7304  bersiaplah era ide-ide brilian visi kenyataan,...   \n",
      "7305  krna paslon islam himbauan nya islam\" tpi susa...   \n",
      "\n",
      "                                           norm_content  \\\n",
      "0     sah, pasangan prabowo-gibran nomor urut 2 dite...   \n",
      "1                                  #nomor 1 amin menang   \n",
      "2     prabowo mengangkat anak penerbang tucano gugur...   \n",
      "3     unboxing prabowo; cerita sejarah, deklarasi bu...   \n",
      "4                            #nomor 1 indonesia beradab   \n",
      "...                                                 ...   \n",
      "7301           yuk dukung nomor urut 3 salah pilih yaaa   \n",
      "7302  kali ketum @partaisocmed merusak suara ulah pe...   \n",
      "7303     tempo takut kalah paslon tetapi majalah berita   \n",
      "7304  bersiaplah era ide-ide brilian visi kenyataan,...   \n",
      "7305  karena paslon islam himbauan nya islam\" tapi s...   \n",
      "\n",
      "                                           stem_content  \n",
      "0     sah pasang prabowo-gibran nomor urut 2 tetap k...  \n",
      "1                                   nomor 1 amin menang  \n",
      "2     prabowo angkat anak terbang tucano gugur anak ...  \n",
      "3     unboxing prabowo cerita sejarah deklarasi budi...  \n",
      "4                                nomor 1 indonesia adab  \n",
      "...                                                 ...  \n",
      "7301           yuk dukung nomor urut 3 salah pilih yaaa  \n",
      "7302  kali tum partaisocmed rusak suara ulah dukung ...  \n",
      "7303     tempo takut kalah paslon tetapi majalah berita  \n",
      "7304  siap era ide brilian visi nyata bawa pimpin ca...  \n",
      "7305  karena paslon islam himbauan nya islam tapi su...  \n",
      "\n",
      "[7306 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5251a55b92d460fa35478067c0ba703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['clean_content'] = samples['stem_content'].progress_apply(lambda x: filtering(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ca33445604f86a5c525222de5a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# samples['clean_stemming'] = samples['filtering'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv( \"hasil/1.DatasetPreprocessing_after_nomorurut_clean_content_23112023.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples.to_csv( \"hasil/samples.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  word_tokens = word_tokenize(text) # Word tokenize\n",
    "  \n",
    "\n",
    "  # Define Indonesian stopwords removal\n",
    "  stop_words = stopwords.words('indonesian')  # NLTK Indonesian stopwords\n",
    "  clean_words = [word for word in word_tokens if word not in stop_words] # stopwords removal\n",
    "  clean_words = ' '.join(clean_words)\n",
    "\n",
    "  words = set(nltk.corpus.words.words())\n",
    "  word_cleaner = word_tokenize(clean_words)\n",
    "  cleaner_words = [w for w in word_cleaner if w.lower() in words or not w.isalpha()] #remove non english\n",
    "  cleaner = ' '.join(cleaner_words)\n",
    "\n",
    "  #stemming with snowball update 07072022 stemmer terakhir\n",
    "#   stem_token=word_tokenize(cleaner)\n",
    "#   stem_words = [snowball.stem(w) for w in stem_token]\n",
    "#   stem_clean= ' '.join(stem_words)\n",
    "\n",
    "  #update13072022 pake lemmatization TextBlob\n",
    "  tblob=TextBlob(clean_words)\n",
    "  lemma= [Word(word).lemmatize(\"v\") for word in tblob.words]\n",
    "  lemma_clean= ' '.join(lemma)\n",
    "\n",
    "  #   cleaner = \" \".join(w for w in nltk.wordpunct_tokenize(clean_words) \\\n",
    "        #   if w.lower() in words or not w.isalpha())\n",
    "\n",
    "  return lemma_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
