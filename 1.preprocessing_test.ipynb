{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load necessary library and module\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text pre-processing to DataFrame\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "snowball = nltk.stem.SnowballStemmer('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StemmerFactory class\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "# stemming process\n",
    "sentence = 'Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan'\n",
    "output   = stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekonomi indonesia sedang dalam tumbuh yang bangga\n"
     ]
    }
   ],
   "source": [
    "# stemming(sentence)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset= pd.read_csv('dataset/DatasetPilpres2024_Twitter_10112023.csv', encoding='ISO-8859-1')\n",
    "samples= pd.read_csv('hasil/samples.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿id</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>user/totalFollowers</th>\n",
       "      <th>user/totalFollowing</th>\n",
       "      <th>user/totalLikes</th>\n",
       "      <th>user/totalTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.830000e+03</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5.830000e+03</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5830.000000</td>\n",
       "      <td>5.830000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.718972e+18</td>\n",
       "      <td>156.454374</td>\n",
       "      <td>4.195540</td>\n",
       "      <td>35.033276</td>\n",
       "      <td>77.761578</td>\n",
       "      <td>2.809121e+05</td>\n",
       "      <td>1576.078559</td>\n",
       "      <td>16623.094511</td>\n",
       "      <td>9.833891e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.023115e+15</td>\n",
       "      <td>1085.247184</td>\n",
       "      <td>36.977125</td>\n",
       "      <td>387.327978</td>\n",
       "      <td>582.525123</td>\n",
       "      <td>1.466068e+06</td>\n",
       "      <td>6913.578377</td>\n",
       "      <td>62187.983826</td>\n",
       "      <td>3.647013e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.607710e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.720430e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.820000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.721740e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.900000e+02</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>2.100000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.721840e+18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.814000e+03</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>3286.000000</td>\n",
       "      <td>2.689975e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.721860e+18</td>\n",
       "      <td>30892.000000</td>\n",
       "      <td>1079.000000</td>\n",
       "      <td>7544.000000</td>\n",
       "      <td>16926.000000</td>\n",
       "      <td>1.105555e+07</td>\n",
       "      <td>191331.000000</td>\n",
       "      <td>828485.000000</td>\n",
       "      <td>2.411624e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ï»¿id         likes       quotes      replies      retweets  \\\n",
       "count  5.830000e+03   5830.000000  5830.000000  5830.000000   5830.000000   \n",
       "mean   1.718972e+18    156.454374     4.195540    35.033276     77.761578   \n",
       "std    8.023115e+15   1085.247184    36.977125   387.327978    582.525123   \n",
       "min    1.607710e+18      0.000000     0.000000     0.000000      0.000000   \n",
       "25%    1.720430e+18      0.000000     0.000000     0.000000      0.000000   \n",
       "50%    1.721740e+18      0.000000     0.000000     0.000000      0.000000   \n",
       "75%    1.721840e+18      3.000000     0.000000     1.000000      1.000000   \n",
       "max    1.721860e+18  30892.000000  1079.000000  7544.000000  16926.000000   \n",
       "\n",
       "       user/totalFollowers  user/totalFollowing  user/totalLikes  \\\n",
       "count         5.830000e+03          5830.000000      5830.000000   \n",
       "mean          2.809121e+05          1576.078559     16623.094511   \n",
       "std           1.466068e+06          6913.578377     62187.983826   \n",
       "min           0.000000e+00             0.000000         0.000000   \n",
       "25%           2.000000e+01            26.000000        55.000000   \n",
       "50%           1.900000e+02           102.000000       285.000000   \n",
       "75%           6.814000e+03           825.000000      3286.000000   \n",
       "max           1.105555e+07        191331.000000    828485.000000   \n",
       "\n",
       "       user/totalTweets  \n",
       "count      5.830000e+03  \n",
       "mean       9.833891e+04  \n",
       "std        3.647013e+05  \n",
       "min        1.000000e+00  \n",
       "25%        2.820000e+02  \n",
       "50%        2.100000e+03  \n",
       "75%        2.689975e+04  \n",
       "max        2.411624e+06  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank = bank[['content', 'score']]\n",
    "# samples=dataset[['tanggal','text']].iloc[1:10]\n",
    "samples=dataset[['tanggal','text','likes','replies','quotes','retweets','searchQuery']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5830 entries, 0 to 5829\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   tanggal      5830 non-null   object\n",
      " 1   text         5830 non-null   object\n",
      " 2   likes        5830 non-null   int64 \n",
      " 3   replies      5830 non-null   int64 \n",
      " 4   quotes       5830 non-null   int64 \n",
      " 5   retweets     5830 non-null   int64 \n",
      " 6   searchQuery  5830 non-null   object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 319.0+ KB\n"
     ]
    }
   ],
   "source": [
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase all text\n",
    "samples['text_lower']=(dataset['text'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanggal                                               10/24/2023\n",
      "text           Bakal calon presiden dan wakil presiden Koalis...\n",
      "likes                                                       2924\n",
      "replies                                                      647\n",
      "quotes                                                       287\n",
      "retweets                                                     441\n",
      "searchQuery                                             #cakimin\n",
      "text_lower     bakal calon presiden dan wakil presiden koalis...\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(samples.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5830 entries, 0 to 5829\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   tanggal      5830 non-null   object\n",
      " 1   text         5830 non-null   object\n",
      " 2   likes        5830 non-null   int64 \n",
      " 3   replies      5830 non-null   int64 \n",
      " 4   quotes       5830 non-null   int64 \n",
      " 5   retweets     5830 non-null   int64 \n",
      " 6   searchQuery  5830 non-null   object\n",
      " 7   text_lower   5830 non-null   object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 364.5+ KB\n"
     ]
    }
   ],
   "source": [
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(stemming(samples.text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??s...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto sunda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??b...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto belaru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??t...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto toto m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>#politik #muhaiminiskandar #cakimin #mahasiswa...</td>\n",
       "      <td>politik muhaiminiskandar cakimin mahasiswaunis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??j...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto japan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal                                               text  \\\n",
       "1  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??s...   \n",
       "2  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??b...   \n",
       "3  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??t...   \n",
       "4  11/7/2023  #politik #muhaiminiskandar #cakimin #mahasiswa...   \n",
       "5  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??j...   \n",
       "\n",
       "                                       clean_content  \n",
       "1  result togel 07 november 2023 jogjatoto sunda ...  \n",
       "2  result togel 07 november 2023 jogjatoto belaru...  \n",
       "3  result togel 07 november 2023 jogjatoto toto m...  \n",
       "4  politik muhaiminiskandar cakimin mahasiswaunis...  \n",
       "5  result togel 07 november 2023 jogjatoto japan ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplex= pd.read_csv('hasil/samples.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_id = stopwords.words('indonesian')\n",
    "len(stopwords_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk langkah stopwords removal\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  clean_word = []\n",
    "  all_text = text.split()\n",
    "  for word in all_text:\n",
    "    if word not in stopwords_id:\n",
    "      clean_word.append(word)\n",
    "  return ' '.join(clean_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46070e8562ca43bf8f49ffe2a4298918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['clean_content'] = samplex['filtering'].progress_apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisasi Kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/normalisasi (1).csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download corpus singkatan\n",
    "# !pip install wget\n",
    "# import wget\n",
    "# wget.download('https://raw.githubusercontent.com/ksnugroho/klasifikasi-spam-sms/master/data/key_norm.csv','dataset/normalisasi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_norm = pd.read_csv('dataset/normalisasi.csv')\n",
    "\n",
    "# Buat fungsi untuk melakukan word normalization\n",
    "def normalisasi(text):\n",
    "  text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0] if (key_norm['singkat'] == word).any() else word for word in text.split()])\n",
    "  text = str.lower(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6f567c60f042c894112fa304597ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['norm_content'] = samples['text_lower'].progress_apply(lambda x: normalisasi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15bd9cf4026410faeda7f5e89da14c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['stem_content'] = samples['norm_content'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>quotes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>norm_content</th>\n",
       "      <th>stem_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#gibran</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??p...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto ??pale...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto palemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#gibran</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??s...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto ??sund...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto sunda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#gibran</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??b...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto ??bela...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto belaru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#gibran</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??t...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto ??toto...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto toto m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>#Politik #MuhaiminIskandar #cakimin #mahasiswa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#cakimin</td>\n",
       "      <td>#politik #muhaiminiskandar #cakimin #mahasiswa...</td>\n",
       "      <td>#politik #muhaiminiskandar #cakimin #mahasiswa...</td>\n",
       "      <td>politik muhaiminiskandar cakimin mahasiswaunis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal                                               text  likes  \\\n",
       "0  11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??P...      0   \n",
       "1  11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??S...      0   \n",
       "2  11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??B...      0   \n",
       "3  11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??T...      0   \n",
       "4  11/7/2023  #Politik #MuhaiminIskandar #cakimin #mahasiswa...      0   \n",
       "\n",
       "   replies  quotes  retweets searchQuery  \\\n",
       "0        0       0         0     #gibran   \n",
       "1        0       0         0     #gibran   \n",
       "2        0       0         0     #gibran   \n",
       "3        0       0         0     #gibran   \n",
       "4        0       0         0    #cakimin   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  result togel 07 november 2023 jogjatoto\\n\\n??p...   \n",
       "1  result togel 07 november 2023 jogjatoto\\n\\n??s...   \n",
       "2  result togel 07 november 2023 jogjatoto\\n\\n??b...   \n",
       "3  result togel 07 november 2023 jogjatoto\\n\\n??t...   \n",
       "4  #politik #muhaiminiskandar #cakimin #mahasiswa...   \n",
       "\n",
       "                                        norm_content  \\\n",
       "0  result togel 07 november 2023 jogjatoto ??pale...   \n",
       "1  result togel 07 november 2023 jogjatoto ??sund...   \n",
       "2  result togel 07 november 2023 jogjatoto ??bela...   \n",
       "3  result togel 07 november 2023 jogjatoto ??toto...   \n",
       "4  #politik #muhaiminiskandar #cakimin #mahasiswa...   \n",
       "\n",
       "                                        stem_content  \n",
       "0  result togel 07 november 2023 jogjatoto palemb...  \n",
       "1  result togel 07 november 2023 jogjatoto sunda ...  \n",
       "2  result togel 07 november 2023 jogjatoto belaru...  \n",
       "3  result togel 07 november 2023 jogjatoto toto m...  \n",
       "4  politik muhaiminiskandar cakimin mahasiswaunis...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>norm_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto\\n\\n??s...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto sunda ...</td>\n",
       "      <td>result togel 07 november 2023 jogjatoto sunda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tanggal                                               text  \\\n",
       "count           9                                                  9   \n",
       "unique          2                                                  9   \n",
       "top     11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??s...   \n",
       "freq            6                                                  1   \n",
       "\n",
       "                                            clean_content  \\\n",
       "count                                                   9   \n",
       "unique                                                  9   \n",
       "top     result togel 07 november 2023 jogjatoto sunda ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                             norm_content  \n",
       "count                                                   9  \n",
       "unique                                                  9  \n",
       "top     result togel 07 november 2023 jogjatoto sunda ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tanggal                                               text  \\\n",
      "1  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??s...   \n",
      "2  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??b...   \n",
      "3  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??t...   \n",
      "4  11/7/2023  #politik #muhaiminiskandar #cakimin #mahasiswa...   \n",
      "5  11/7/2023  result togel 07 november 2023 jogjatoto\\n\\n??j...   \n",
      "6  11/6/2023  bacapres anies baswedan belum menunjuk ketua t...   \n",
      "7  11/7/2023  hanya ganjar yang konsisten tolak israel datan...   \n",
      "8  11/6/2023  nakama ga matten da! jama su na! ??? [sebuah u...   \n",
      "9  11/6/2023  bertemu din syamsuddin, cak imin klaim menang ...   \n",
      "\n",
      "                                       clean_content  \\\n",
      "1  result togel 07 november 2023 jogjatoto sunda ...   \n",
      "2  result togel 07 november 2023 jogjatoto belaru...   \n",
      "3  result togel 07 november 2023 jogjatoto toto m...   \n",
      "4  politik muhaiminiskandar cakimin mahasiswaunis...   \n",
      "5  result togel 07 november 2023 jogjatoto japan ...   \n",
      "6  bacapres anies baswedan belum tunjuk ketua tpn...   \n",
      "7  hanya ganjar yang konsisten tolak israel datan...   \n",
      "8  nakama ga matten da jama su na buah utas nakam...   \n",
      "9  temu din syamsuddin cak imin klaim menang 1 pu...   \n",
      "\n",
      "                                        norm_content  \n",
      "1  result togel 07 november 2023 jogjatoto sunda ...  \n",
      "2  result togel 07 november 2023 jogjatoto belaru...  \n",
      "3  result togel 07 november 2023 jogjatoto toto m...  \n",
      "4  politik muhaiminiskandar cakimin mahasiswaunis...  \n",
      "5  result togel 07 november 2023 jogjatoto jepang...  \n",
      "6  bacapres anies baswedan belum tunjuk ketua tpn...  \n",
      "7  hanya ganjar yang konsisten tolak israel datan...  \n",
      "8  nakama tidak matten da jama su na buah utas na...  \n",
      "9  temu din syamsuddin cak imin klaim menang 1 pu...  \n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a89c2d11d04f478745a7cdf3f50b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['filtering'] = samples['stem_content'].progress_apply(lambda x: filtering(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ca33445604f86a5c525222de5a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# samples['clean_stemming'] = samples['filtering'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv( \"hasil/samples_clean_content.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv( \"hasil/samples.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  word_tokens = word_tokenize(text) # Word tokenize\n",
    "  \n",
    "\n",
    "  # Define Indonesian stopwords removal\n",
    "  stop_words = stopwords.words('english')  # NLTK Indonesian stopwords\n",
    "  clean_words = [word for word in word_tokens if word not in stop_words] # stopwords removal\n",
    "  clean_words = ' '.join(clean_words)\n",
    "\n",
    "  words = set(nltk.corpus.words.words())\n",
    "  word_cleaner = word_tokenize(clean_words)\n",
    "  cleaner_words = [w for w in word_cleaner if w.lower() in words or not w.isalpha()] #remove non english\n",
    "  cleaner = ' '.join(cleaner_words)\n",
    "\n",
    "  #stemming with snowball update 07072022 stemmer terakhir\n",
    "#   stem_token=word_tokenize(cleaner)\n",
    "#   stem_words = [snowball.stem(w) for w in stem_token]\n",
    "#   stem_clean= ' '.join(stem_words)\n",
    "\n",
    "  #update13072022 pake lemmatization TextBlob\n",
    "  tblob=TextBlob(clean_words)\n",
    "  lemma= [Word(word).lemmatize(\"v\") for word in tblob.words]\n",
    "  lemma_clean= ' '.join(lemma)\n",
    "\n",
    "  #   cleaner = \" \".join(w for w in nltk.wordpunct_tokenize(clean_words) \\\n",
    "        #   if w.lower() in words or not w.isalpha())\n",
    "\n",
    "  return lemma_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
