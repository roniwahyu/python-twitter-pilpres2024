{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package words to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/gitpod/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Load necessary library and module\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text pre-processing to DataFrame\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "snowball = nltk.stem.SnowballStemmer('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StemmerFactory class\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "# stemming process\n",
    "sentence = 'Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan'\n",
    "output   = stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('dataset/DatasetPilpres2024_Twitter_10112023.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank = bank[['content', 'score']]\n",
    "samples=dataset[['tanggal','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=(dataset[:10]['text'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekonomi indonesia sedang dalam tumbuh yang bangga\n"
     ]
    }
   ],
   "source": [
    "# stemming(sentence)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\n",
      "\n",
      "??JAPAN POOLS??\n",
      "??6496??\n",
      "\n",
      "DI COBA HOKI NYA BERSAMA JOGJATOTO Link : https://jogja,.com\n",
      "\n",
      "#hasilresulttogel #resulttogel #resulttogelwla\n",
      "#Gibran #Hujan #Undip #prabowo #Minggu #togelwla #jogjatoto #hasilresultjogjatoto #CHONBURIPOOLS\n"
     ]
    }
   ],
   "source": [
    "print(samples.text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5830</td>\n",
       "      <td>5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>104</td>\n",
       "      <td>4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>11/7/2023</td>\n",
       "      <td>#JokowiMenyerahlah Mundurlah Ketua MK #FreePal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3260</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tanggal                                               text\n",
       "count        5830                                               5830\n",
       "unique        104                                               4010\n",
       "top     11/7/2023  #JokowiMenyerahlah Mundurlah Ketua MK #FreePal...\n",
       "freq         3260                                                 37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result togel 07 november 2023 jogjatoto sunda pools 5279 di coba hoki nya sama jogjatoto link https jogja com hasilresulttogel resulttogel resulttogelwla gibran hujan undip prabowo minggu togelwla jogjatoto hasilresultjogjatoto chonburipools\n"
     ]
    }
   ],
   "source": [
    "print(stemming(samples.text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tanggal                                               text\n",
      "0     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??P...\n",
      "1     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??S...\n",
      "2     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??B...\n",
      "3     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??T...\n",
      "4     11/7/2023  #Politik #MuhaiminIskandar #cakimin #mahasiswa...\n",
      "...         ...                                                ...\n",
      "5825  11/7/2023  Jakarta Timur pilih Prabowo-Gibran, info dari ...\n",
      "5826  11/7/2023  Abu Janda, sosok yang menggetarkan koalisi Pra...\n",
      "5827  11/7/2023  Konflik ini membuat Prabowo-Gibran harus beker...\n",
      "5828  11/7/2023  Prabowo-Gibran 2024, Indonesia sejahtera lewat...\n",
      "5829  11/6/2023  Titiek Suharto Jabat Penasihat TKN Prabowo-Gib...\n",
      "\n",
      "[5830 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b9a32617834cd1a4e8852446a3a637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['clean_content'] = samples['text'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    result togel 07 november 2023 jogjatoto palemb...\n",
       "1    result togel 07 november 2023 jogjatoto sunda ...\n",
       "2    result togel 07 november 2023 jogjatoto belaru...\n",
       "3    result togel 07 november 2023 jogjatoto toto m...\n",
       "4    politik muhaiminiskandar cakimin mahasiswaunis...\n",
       "Name: clean_content, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['clean_content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5830 entries, 0 to 5829\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tanggal        5830 non-null   object\n",
      " 1   text           5830 non-null   object\n",
      " 2   clean_content  5830 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.8+ KB\n"
     ]
    }
   ],
   "source": [
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tanggal                                               text  \\\n",
      "0     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??P...   \n",
      "1     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??S...   \n",
      "2     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??B...   \n",
      "3     11/7/2023  RESULT TOGEL 07 NOVEMBER 2023 JOGJATOTO\\n\\n??T...   \n",
      "4     11/7/2023  #Politik #MuhaiminIskandar #cakimin #mahasiswa...   \n",
      "...         ...                                                ...   \n",
      "5825  11/7/2023  Jakarta Timur pilih Prabowo-Gibran, info dari ...   \n",
      "5826  11/7/2023  Abu Janda, sosok yang menggetarkan koalisi Pra...   \n",
      "5827  11/7/2023  Konflik ini membuat Prabowo-Gibran harus beker...   \n",
      "5828  11/7/2023  Prabowo-Gibran 2024, Indonesia sejahtera lewat...   \n",
      "5829  11/6/2023  Titiek Suharto Jabat Penasihat TKN Prabowo-Gib...   \n",
      "\n",
      "                                          clean_content  \n",
      "0     result togel 07 november 2023 jogjatoto palemb...  \n",
      "1     result togel 07 november 2023 jogjatoto sunda ...  \n",
      "2     result togel 07 november 2023 jogjatoto belaru...  \n",
      "3     result togel 07 november 2023 jogjatoto toto m...  \n",
      "4     politik muhaiminiskandar cakimin mahasiswaunis...  \n",
      "...                                                 ...  \n",
      "5825  jakarta timur pilih prabowo-gibran info dari s...  \n",
      "5826  abu janda sosok yang getar koalisi prabowo-gib...  \n",
      "5827  konflik ini buat prabowo-gibran harus kerja sa...  \n",
      "5828  prabowo-gibran 2024 indonesia sejahtera lewat ...  \n",
      "5829  titiek suharto jabat nasihat tkn prabowo-gibra...  \n",
      "\n",
      "[5830 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv( \"hasil/samples.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cae702700749d280c1657a00d7095c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['filtering'] = samples['text'].progress_apply(lambda x: filtering(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5aea22bd8d471398359562a999f50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples['clean_content_filter'] = samples['filtering'].progress_apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv( \"hasil/samples.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "  text = text.lower()                                   # Lowercase all sentences\n",
    "      #   text = text.strip()                                   # Remove whitespace\n",
    "  text = re.sub('[-+]?[0-9]+', ' ', text)               # Remove numbers \n",
    "  text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    # Remove URLs\n",
    "  text = re.sub(r\"pic.twitter.com\\S+\", ' ', text)       # Remove custom URLs for twitter\n",
    "  text = re.sub(r'\\@([\\w]+)',' ', text)                 # Remove Mention @\n",
    "  text = re.sub(r'\\#([\\w]+)',' ', text)                 # Remove #TAGAR\n",
    "  text = re.sub('\\S*@\\S*\\s?', ' ', text)                # Remove email\n",
    "  text = re.sub(r'[^\\w\\s]', ' ', text)                  # Remove punctuation\n",
    "      #   text = re.sub(r'\\b\\w{1,3}\\b','',text)                 #Remove n-chars,Remove less than 3 chars, minimum 4 character allowed \"\\b[a-zA-Z0-9]{3}\\b\"\n",
    "  text = re.sub(r'[!$%^&*@#()_+|~=`{}\\[\\]%\\-:\";\\'<>?,.\\/]', ' ', text)  # Tahap-5: simbol\n",
    "      #   text = re.sub(r'[0-9]+','', text)                     # Tahap-6: angka\n",
    "  text = re.sub(r'([a-zA-Z])\\1\\1','\\\\1', text)          # Tahap-7: koreksi duplikasi tiga karakter beruntun atau lebih (contoh. yukkk)\n",
    "  text = re.sub(' +',' ', text)                         #remove multiple whitespace\n",
    "  text = re.sub(r'^[ ]|[ ]$','', text)                  # Tahap-9: spasi di awal dan akhir kalimat\n",
    "\n",
    "  # text = re.sub('\\b[a-zA-Z0-9]{3}\\b','',text)\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') # Remove non-ascii character\n",
    "  word_tokens = word_tokenize(text) # Word tokenize\n",
    "  \n",
    "\n",
    "  # Define Indonesian stopwords removal\n",
    "  stop_words = stopwords.words('english')  # NLTK Indonesian stopwords\n",
    "  clean_words = [word for word in word_tokens if word not in stop_words] # stopwords removal\n",
    "  clean_words = ' '.join(clean_words)\n",
    "\n",
    "  words = set(nltk.corpus.words.words())\n",
    "  word_cleaner = word_tokenize(clean_words)\n",
    "  cleaner_words = [w for w in word_cleaner if w.lower() in words or not w.isalpha()] #remove non english\n",
    "  cleaner = ' '.join(cleaner_words)\n",
    "\n",
    "  #stemming with snowball update 07072022 stemmer terakhir\n",
    "#   stem_token=word_tokenize(cleaner)\n",
    "#   stem_words = [snowball.stem(w) for w in stem_token]\n",
    "#   stem_clean= ' '.join(stem_words)\n",
    "\n",
    "  #update13072022 pake lemmatization TextBlob\n",
    "  tblob=TextBlob(clean_words)\n",
    "  lemma= [Word(word).lemmatize(\"v\") for word in tblob.words]\n",
    "  lemma_clean= ' '.join(lemma)\n",
    "\n",
    "  #   cleaner = \" \".join(w for w in nltk.wordpunct_tokenize(clean_words) \\\n",
    "        #   if w.lower() in words or not w.isalpha())\n",
    "\n",
    "  return lemma_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
